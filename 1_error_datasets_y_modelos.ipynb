{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sets de entrenamiento y Modelos\n",
    "* Link github: https://github.com/sebastiandres/ia_notebooks/1_error_datasets_y_modelos.ipynb\n",
    "* Link mybinder: https://bit.ly/2Vf89oC\n",
    "\n",
    "## Sobre jupyter notebook\n",
    "\n",
    "Jupyter notebooks es un medio de desarrollo iterativo, que  permite mezclar código con texto, imágenes y video. \n",
    "Su facilidad de uso permite crear y descargar material para el aprendizaje individual y grupal.\n",
    "\n",
    "*Importante*: cada celda se ejecuta con  `Alt + Enter` \n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "1. Importancia de conocer el negocio y explorar los datos.\n",
    "2. Técnicas para seleccionar un modelo predictivo.\n",
    "3. Conocer el significado y utilidad de:\n",
    "    * Datos de entrenamiento\n",
    "    * Datos de validación (verificación)\n",
    "    * Datos de testeo\n",
    "    * Datos de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Verificar disponibilidad de librerías y probar jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib  import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Versión de pandas: \", pd.__version__)\n",
    "print(\"Versión de numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed so everyone can reproduce the same results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de celdas de jupyter notebook con python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, i**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar funcionalidades pre-existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos pueden estar en un archivo csv o excel, o haberse descargado de intenet, o haberlos obtenido después de un largo proceso de proccesamiento. En esta caso, se obtienen simplemente con una función creada para este objetivo:\n",
    "\n",
    "`def get_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data = 200\n",
    "x_all, y_all = get_data(N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns=[\"x\",\"y\"], data=np.array([x_all, y_all]).T)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué cosa le llama la atención de los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Porqué siempre es bueno el análisis gráfico?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe un ejemplo clásico llamado el Cuarteto de Anscombe. \n",
    "\n",
    "Considere los siguientes 4 conjuntos de datos. \n",
    "¿Qué puede decir de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "filepath = os.path.join(\"data\",\"anscombe.csv\")\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción de los datos, versión numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filepath = os.path.join(\"data\",\"anscombe.csv\")\n",
    "data = np.loadtxt(filepath, delimiter=\",\", skiprows=1)\n",
    "for i in range(4):\n",
    "    x = data[:,2*i]\n",
    "    y = data[:,2*i+1]\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    print(\"Grupo %d:\" %(i+1))\n",
    "    print(\"\\tTiene pendiente m=%.2f e intercepto b=%.2f\" %(slope, intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción de los datos, versión pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "filepath = os.path.join(\"data\",\"anscombe.csv\")\n",
    "df = pd.read_csv(filepath)\n",
    "df[sorted(df.columns)].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Veamos ahora que nos puede decir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def my_plot():\n",
    "    filepath = os.path.join(\"data\",\"anscombe.csv\")\n",
    "    data = np.loadtxt(filepath, delimiter=\",\", skiprows=1)\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for i in range(4):\n",
    "        x = data[:,2*i]\n",
    "        y = data[:,2*i+1]\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.plot(x,y,'o')\n",
    "        plt.xlim([2,20])\n",
    "        plt.ylim([2,20])\n",
    "        plt.title(\"Grupo %d\" %(i+1))\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        x_aux = np.linspace(2,16,20)\n",
    "        plt.plot(x_aux, m*x_aux + b, 'r', lw=2.0)\n",
    "    plt.suptitle(\"Cuarteto de Anscombe\")\n",
    "    plt.show()\n",
    "    \n",
    "my_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis gráfico\n",
    "Una de las primeras tareas que debemos hacer es realizar un análisis gráfico de los datos. Para esto existen muchas alternativas. Use su buen juicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x_all, y_all, \"-\", label=\"row data\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lección 1: Los datos no suelen venir ordenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_index = np.argsort(x_all)\n",
    "x_sorted = np.array(x_all)[sorting_index]\n",
    "y_sorted = np.array(y_all)[sorting_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x_sorted, y_sorted, \"-\", label=\"sorted data\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x_sorted[:100], y_sorted[:100], \"-\", label=\"sorted data\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando los datos\n",
    "\n",
    "Después de ordenar, también es necesario eliminar los datos nulos (y valores fuera de rango)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(x_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_nan = np.logical_or(np.isnan(x_sorted), np.isnan(y_sorted))\n",
    "m_not_nan = np.logical_not(m_nan)\n",
    "x = x_sorted[m_not_nan]\n",
    "y = y_sorted[m_not_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ajustando un modelo simple\n",
    "\n",
    "Si definimos el grado del polinomio, es posible ajustar los coeficientes del polinomio para que \"trate de pasar\" por los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a polinomial fit\n",
    "N = 1\n",
    "z = np.polyfit(x, y, N)\n",
    "polinomio = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomio(np.array([0., 1., 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomio(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.plot(x, y, '-', lw=2.0, label=\"data\")\n",
    "plt.plot(x, polinomio(x),'-', lw=2.0, label=\"model\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar distintos valores de N: 1, 5, 10, 50, 100\n",
    "N = 50 \n",
    "z = np.polyfit(x, y, N)\n",
    "polinomio = np.poly1d(z)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x, y, '-', lw=2.0, label=\"data\")\n",
    "plt.plot(x, polinomio(x),'-', lw=2.0, label=\"model\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué valor debemos usar para N? ¿Cómo podemmos elegirlo *científicamente*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando el error\n",
    "\n",
    "El valor de error a utilizar depende del contexto del problema. Existen 2 errores habituales para este tipo de problemas de regresión:\n",
    "* Error Absoluto Medio - Mean Absolute Error (MAE): \n",
    "\n",
    "$$\\frac{1}{n} \\sum_{i=1}^n |y_i - f(x_i)|$$\n",
    "\n",
    "* Error Cuadrático Medio -Mean Squared Error (MSE): \n",
    "\n",
    "$$\\frac{1}{n} \\sum_{i=1}^n (y_i - f(x_i) )^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the error\n",
    "def mae_from_model(x, y, model):\n",
    "    m_nan = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    m_not_nan = np.logical_not(m_nan)\n",
    "    x_ = x[m_not_nan]\n",
    "    y_ = y[m_not_nan]\n",
    "    y_model_ = model(x_)\n",
    "    mae = np.sum(np.abs(y_ - y_model_)) / len(y_)\n",
    "    return mae\n",
    "\n",
    "def mse_from_model(x, y, model):\n",
    "    m_nan = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    m_not_nan = np.logical_not(m_nan)\n",
    "    x_ = x[m_not_nan]\n",
    "    y_ = y[m_not_nan]\n",
    "    y_model_ = model(x_)\n",
    "    mse = np.sum((y_ - y_model_)**2) / len(y_)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cuanto error tienen los modelos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "z = np.polyfit(x, y, N)\n",
    "model_N = np.poly1d(z)\n",
    "print(\"Mean Absolute Error (MAE) for N={}: {}\".format(N, mae_from_model(x, y, model_N)))\n",
    "print(\"Mean Squared Error (MSE) for N={}: {}\".format(N, mse_from_model(x, y, model_N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos errores son dos formas válidas de medir el error. No existe una manera correcta de medir el error. Depende del contexto y del problema.\n",
    "\n",
    "En realidad, los coeficientes del polinomio se encuentran minimizando el Mean Squared Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ya estábamos utilizando una forma de medir el error sin saberlo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recapitulemos: \n",
    "* No sabemos a priori cuál es el grado del polinomio.\n",
    "* Si se fija un grado del polinomio, los coeficientes se encuentran minimizando el error cuadrático medio.\n",
    "\n",
    "Lo anterior es frecuente en todos los modelos de Machine Learning:\n",
    "* Los parámetros de un modelo se llaman **metaparámetros**. \n",
    "Son ciertos parámetros que se definen pero no forman parte de los valores que se ajustarán con los datos.\n",
    "* Una vez definidos los metaparámetros, se buscan los valores de los parámetros. \n",
    "\n",
    "Las librerías proporcionan métodos sencillos para ajustar un modelo específico, pero encontrar los metaparámetros resulta en general un desafío más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eligiendo el valor de N\n",
    "\n",
    "En el caso de nuestro problema de juguete, queremos encontrar el metaparámetro $N$: el grado del polinomio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(range(1,25))\n",
    "mse = []\n",
    "for N in degrees:\n",
    "    model = np.poly1d(np.polyfit(x, y, N))\n",
    "    mse_error = mse_from_model(x, y, model) \n",
    "    mse.append(mse_error)\n",
    "    print(N, mse_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(degrees, mse, 'o-', label=\"Train error\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de lo anterior, sería razonable pensar que tenemos que tomar un polinomio suficientemente grande. \n",
    "\n",
    "Lo anterior es una clásica falacia o error de entrenamiento de modelos.\n",
    "\n",
    "***Lo que buscamos no es un modelo que explique perfectamente el pasado, sino que logre predecir razonablemente bien el futuro.***\n",
    "\n",
    "Todo polinomio o modelo extremandamente complejo logrará reproducir perfectamente los datos conocidos. La simple memorización de los resultados cumple ese objetivo. \n",
    "\n",
    "La tarea de los modelos de Machine Learning es generalizar. Como, a partir de ejemplos, es posible aprender parámetros que lograrán una predicción acertada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets de entrenamiento, validación, verificación, predicción\n",
    "\n",
    "En el entrenamiento de modelos de Machine Learning, resulta común dividir los datos en conjuntos con distintas finalidades:\n",
    "* **Set de entrenamiento (Training set)**: Set utilizado para entrenar el modelo, asumiento conocidos los metaparámetros.\n",
    "* **Set de verificación/validación (validation set)**:  Set utilizado para evaluar el modelo y comparar metaparámetros.\n",
    "* **Set de testeo (test set)**: Set para estimar el error de predicción del modelo, una vez seleccionado.\n",
    "\n",
    "La división de los datos conocidos en conjuntos de entrenamiento - validación - testeo se hace en relación 60%-20%-20% o 80%-10%-10%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_vt, y_train, y_vt = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_vt, y_vt, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape[0], y_train.shape[0], 100*x_train.shape[0]/x.shape[0])\n",
    "print(x_val.shape[0], y_val.shape[0], 100*x_val.shape[0]/x.shape[0])\n",
    "print(x_test.shape[0], y_test.shape[0], 100*x_test.shape[0]/x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(range(1,25))\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "values = []\n",
    "for n in degrees:\n",
    "    coeffs = np.polyfit(x_train, y_train, n)\n",
    "    model_n = np.poly1d(coeffs)\n",
    "    mse_train.append(mse_from_model(x_train, y_train, model_n))\n",
    "    mse_test.append(mse_from_model(x_test, y_test, model_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(degrees, mse_train,'x-', lw=2.0, label=\"train\")\n",
    "plt.plot(degrees, mse_test,'o-', lw=2.0, label=\"test\")\n",
    "plt.xlabel(\"N (grado polinomio)\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.ylim([0, 1.1*max(max(mse_train), max(mse_test))])\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al combinar un set de entrenamiento con un set de contraste o validación, podemos ver que aumentar el grado del polinomio no es ventajoso. De hecho y como resultaba intuitivo, resulta mejor considerar un modelo más bien simple: una recta o un relación cuadrática.\n",
    "En general, conviene aplicar la navaja de Occam: *En igualdad de condiciones, la explicación más sencilla suele ser la más probable.*  Entre dos modelos que tienen una capacidad predictiva similar, conviene tomar el más simple de ambos (con menos parámetros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error del modelo podemos indicarlo considerando el conjunto de testeo y el conjunto de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "coeffs_N = np.polyfit(x_train, y_train, N)\n",
    "model_N = np.poly1d(coeffs_N)\n",
    "print(\"Mean Absolute Error (MAE) for N={}: {}\".format(N, mae_from_model(x_test, y_test, model_N)))\n",
    "print(\"Mean Squared Error (MSE) for N={}: {}\".format(N, mse_from_model(x_test, y_test, model_N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Como se comportaría el modelo en un conjunto distinto de datos?\n",
    "\n",
    "Uno de los grandes problemas que se tiene en Machine Learning es que a veces no se posee un control perfecto del dataset donde se realizará la predicción. Por ejemplo, si se trata de un modelo que trabaja con fotografías, el modelo puede haberse entrenado en fotografías de buena calidad e iluminación, pero debe trabajar además con fotografías borrosas o con baja iluminación.\n",
    "\n",
    "La única forma que un modelo funcione de la misma manera en el conjunto de datos de entrenamiento y predicción (producción) es que estos sean tan parecidos como sea posible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "N = 1\n",
    "coeffs_N = np.polyfit(x_train, y_train, N)\n",
    "model_N = np.poly1d(coeffs_N)\n",
    "# Get new data\n",
    "x_new, y_new = get_data(N_data=100, xmin=100, xmax=200)\n",
    "y_pred = model_N(x_new)\n",
    "print(\"Mean Squared Error (MSE) for N={}: {}\".format(N, mse_from_model(x_new, y_pred, model_N)))\n",
    "# Plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x_new, y_pred, \"x\", lw=2.0, label=\"model\")\n",
    "plt.plot(x_new, y_new, \"o\", lw=2.0, label=\"true\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad:\n",
    "¿Qué pasa si usando un valor distinto de N? \n",
    "\n",
    "Volver a ejecutar todas las celdas, pero ahora con N_datos=10000. \n",
    "\n",
    "¿Qué cosas son diferentes esta vez?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**: Hacer doble click y reponder aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moralejas:\n",
    "* Resulta necesario entrenar el modelo en conjuntos de datos claramente diferenciados para poder optimizar y elegir los mejores parámetros sin sobreajustar los parámetros.\n",
    "* Cada conjunto tiene una finalidad específica distinta.\n",
    "* Tener más datos siempre es bueno, pero no reemplaza conocer como entrenar bien un modelo y conocer sus limitaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encuesta\n",
    "[Link](https://forms.office.com/Pages/ResponsePage.aspx?id=zu7OdUTRPU-clJ5rQCX8_4qs5cX1Y7dFhVdiCz848sBUMkowMkU2UjlYUjczWjFBQjMwWktBMFBHMS4u)\n",
    "\n",
    "<img src=\"images/QR.png\" alt=\"QR\" width=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
