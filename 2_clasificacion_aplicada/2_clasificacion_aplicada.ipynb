{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Clasificación usando Machine Learning\n",
    "\n",
    "* Link github: https://github.com/sebastiandres/ia_notebooks/blob/master/2_clasificacion_aplicada/2_clasificacion_aplicada.ipynb\n",
    "* Link mybinder: https://bit.ly/38ZbgnV\n",
    "\n",
    "\n",
    "## Sobre jupyter notebook\n",
    "\n",
    "Jupyter notebooks es un medio de desarrollo iterativo, que  permite mezclar código con texto, imágenes y video. \n",
    "Su facilidad de uso permite crear y descargar material para el aprendizaje individual y grupal.\n",
    "\n",
    "*Importante*: cada celda se ejecuta con  `Alt + Enter` \n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "1. Entender cómo funcionan los modelos de clasificación.\n",
    "2. Entrenamiento práctico de un modelo de clasificación.\n",
    "3. Análisis desde el punto de vista del negocio.\n",
    "\n",
    "Nuestra primera tarea será verificar que tenemos las librerías necesarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import altair as alt\n",
    "print(\"Pandas version\", pd.__version__)\n",
    "print(\"Altair version\", alt.__version__)\n",
    "from sklearn import __version__ as sklearn_version\n",
    "print(\"Sklearn version\", sklearn_version)\n",
    "\n",
    "from time import time\n",
    "\n",
    "np.random.seed(42)\n",
    "alt.themes.enable(\"opaque\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Caso Práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Se utilizará un conjunto de datos relacionados con campañas de marketing directo (llamadas telefónicas) de una institución bancaria portuguesa. El objetivo de la clasificación es predecir si el cliente suscribirá un depósito a plazo.\n",
    "\n",
    "Los datos se pueden encontrar en el siguiente [link](https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing), pero ya se encuentran descargados localmente en la carpeta `data`, por lo que ya se encuentran disponibles en este notebook.\n",
    "\n",
    "Para realizar tal labor se procederá de la siguiente manera:\n",
    "\n",
    "1. Lectura de datos\n",
    "2. Análisis descriptivo\n",
    "3. Visualizaciones\n",
    "4. Pre-procesamiento\n",
    "5. Modelo de Clasificación\n",
    "6. Interpretación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1. Lectura de Datos\n",
    "\n",
    "Para leer el archivo existen múltiples opciones. Pandas nos entrega una manera sencilla de leer los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Generar la ruta\n",
    "filepath = os.path.join(\"data\", \"bank-full.csv\")\n",
    "# Leer los datos en el filetpath  y con el separador ;\n",
    "bank = pd.read_csv(filepath, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las columnas\n",
    "bank.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver el tamaño del dataset\n",
    "bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "El archivo `bank-names.txt` nos entrega toda la información detallada al conjunto de datos a utilizar. En particular nos interesa el punto 7, donde se definen las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%cat data/bank-names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen**:\n",
    "\n",
    "* Los datos se relacionan con marketing directo de una institucion bancaria. Las campañas de marketing \n",
    "\n",
    "* El dataset completo (bank-full.csv) tiene 45,211 ejemplos (elementos de aprendizaje). Cada ejemplo tiene 16 atributos (x) y un valor a predecir (y): yes/no.\n",
    "\n",
    "**ATRIBUTOS**\n",
    "* Bank client data:\n",
    "   1. age (numeric)\n",
    "   2. job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "   3. marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "   4. education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "   5. default: has credit in default? (binary: \"yes\",\"no\")\n",
    "   6. balance: average yearly balance, in euros (numeric) \n",
    "   7. housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "   8. loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "\n",
    "  * Related with the last contact of the current campaign:\n",
    "   9. contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "   10. day: last contact day of the month (numeric)\n",
    "   11. month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "   12. duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "\n",
    "  * Otros:\n",
    "   13. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "   14. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "   15. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "   16. poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "* Variable \"y\" a predecir: ¿El cliente suscribió un depósito a plazo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2. Análisis Descriptivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Lo primero es saber las columnas utilizadas, si es que poseen elementos nulos y el tipo de columna. Adicionalmente se puede obtener la cantidad de memoria RAM utilizada por este dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bank.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Luego sigue un análisis descriptivo de los datos, como ver medidas de dispersión (mínimo, máximo, promedio, etc.) para datos numéricos y medidas de frecuencia para datos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bank.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Usar fillna(\"\") permite enmascarar los nans y solo observar los valores existentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.describe(include=\"all\").fillna(\"\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Algunos análisis sobre nuestra variable de interés `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bank[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank[\"y\"].value_counts().pipe(lambda s: s[\"no\"] / s[\"yes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cada 7.5 \"no\" (approximadamente) hay un \"yes\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bank[\"y\"].value_counts().pipe(lambda s: s[\"yes\"] / s.sum() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Sólo hay alrededor de un 11% de datos positivos, en la literatura se suele decir que es un conjunto de datos __desbalanceado__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Veamos como se distribuyen los datos numéricos respecto a la variable de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de columnas de tipo numéricas\n",
    "numeric_columns = bank.select_dtypes(\"number\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es posible concatenar los strings con un caracter (o string) común:\n",
    "\" / \".join(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if X.shape[0]<6000:\n",
    "    # Gráfico con Altair\n",
    "    alt.Chart(bank).mark_circle(opacity=0.3).encode(\n",
    "        x=alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "        y=alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "        color='y:N'\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=200\n",
    "    ).repeat(\n",
    "        row=numeric_columns,\n",
    "        column=numeric_columns\n",
    "    )\n",
    "else:\n",
    "    # Gráfico con pandas y matplotlib\n",
    "    colors=['blue','orange']\n",
    "    scatter_matrix(X[numeric_columns], figsize=(16, 16), alpha=0.3, diagonal='kde', c=y.apply(lambda x: colors[x]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Ahora con los datos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Selección de columnas de tipo objeto (categóricas)\n",
    "object_columns = bank.drop(columns=\"y\").select_dtypes(\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es posible concatenar los strings con un caracter (o string) común:\n",
    "\" / \".join(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X.shape[0]<6000:\n",
    "    # Graficar con Altair\n",
    "    alt.Chart(bank).mark_bar().encode(\n",
    "        x=alt.X(alt.repeat(\"row\"), type='nominal'),\n",
    "        y='count()', #y='count()',\n",
    "        color='y:N'\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300\n",
    "    ).repeat(\n",
    "        row=object_columns,\n",
    "    )\n",
    "else:\n",
    "    # Gráfico con pandas y matplotlib\n",
    "    pass\n",
    "    # X[\"job\"].value_counts().plot.bar(stacked=True);\n",
    "    #colors=['blue','orange']\n",
    "    #scatter_matrix(X[object_columns], figsize=(16, 16), alpha=0.3, diagonal='kde', c=y.apply(lambda x: colors[x]));    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 4. Pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "En esta sección se realizarán una serie de manipulación a los datos, con tal de implementar los modelos de clasificación en la siguien etapa. \n",
    "\n",
    "Los procesos típicos consideran definir la matriz de diseño `X`, el vector de respuesta `y`, dividir en conjunto de entrenamiento-test, realizar modificaciones a algunas columnas e incluso definir un _pipeline_ de transformaciones a realizar al conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Se define la matriz de diseño y el vector de respuesta de forma usual, salvo que la variable `y` tendrá datos 0 y 1, en lugar de _no_ y _yes_, esto por practicidad a la hora de implementar las métricas de evaluación del desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = bank.drop(columns=\"y\")\n",
    "y_label_dict = {\"yes\": 1, \"no\": 0}\n",
    "y = bank[\"y\"].map(y_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Veamos la matriz X que seleccionamos\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Mirar las primeros n filas\n",
    "y.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Se realiza la división de los sets de entrenamiento-test a razón de 80-20 y de manera estratificada dada la cantidad de datos que disponemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una división estratificada permite que los datasets que se generan posean una distribución similar. De otra manera, podría suceder sucedería que los conjunto de entrenamiento y test tendrían distribuciones distintas al conjunto completo, con un sezgo no real que se traspasaría al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Revisemos que la división estratificada se hizo correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f\"La razón entre valores 'no' y 'yes'  en el conjunto de entrenamiento es {y_train.value_counts().pipe(lambda s: s[0] / s[1]):.1f}\")\n",
    "print(f\"Porcentaje de valores 'yes' en el conjunto de entrenamiento es {y_train.value_counts().pipe(lambda s: 100*s[1] / s.sum()):.1f}%\")\n",
    "print(f\"La razón entre valores 'no' y 'yes' en el conjunto de test es {y_test.value_counts().pipe(lambda s: s[0] / s[1]):.1f}\")\n",
    "print(f\"Porcentaje de valores 'yes' en el conjunto de entrenamiento es {y_test.value_counts().pipe(lambda s: 100*s[1] / s.sum()):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "En cuento al *workflow*, una buena práctica es realizar la definición de pasos a seguir en un clasificador utilizando `Pipeline` ([documentación](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)). En nuestro caso primero se definen una serie de transformaciones y luego el modelo clasificador a utilizar.\n",
    "\n",
    "Entonces, primero se definen las transformaciones que se realizarán.\n",
    "\n",
    "* Columnas numéricas se escalan.\n",
    "* Columnas categóricas se codifican utilizando la técnica _One Hot Encoding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columnas numéricas:\", \", \".join(numeric_columns))\n",
    "print(\"Columnas categóricas:\", \", \".join(object_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[('scaler', StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('onehot', OneHotEncoder())]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, object_columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.1 Una primera clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Se crea un clasificador que considera la transformación anterior y además una regresión logística. En general, se suele considerar una buena práctica aplicar un modelo conocido base como regresión logísticas antes de utilizar modelos más complejos, puesto que permite tener una idea de la complejidad del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=200))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Entrenamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finalmente obtenemos el _score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f\"El score del modelo utilizando Regresión Logística es {clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento del modelo fue extremadamente eficiente. A pesar de considerar +45,000 ejemplos, tomó menos de un segundo. Más precisamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "toc = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "tic = time.time()\n",
    "print(\"Entrenamiento tomó {} segundos\".format(tic-toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Una manera gráfica de ver los resultados es utilizando la **Matriz de Confusión**, que puede aplicarse tanto al conjunto de entrenamiento como al conjunto de predicción: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "print(\"Conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Conjunto de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusión para valores totales - dataset de predicción\n",
    "cm = plot_confusion_matrix(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cmap=plt.cm.Blues,\n",
    "    values_format=\".0f\",\n",
    "    #normalize = \"all\", # all, pred, true\n",
    ")\n",
    "cm.ax_.set_title(\"Matriz de confusión utilizando Regresión Logística\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/prediction_error.jpeg)\n",
    "\n",
    "La interpretación de una matriz de confusión es la siguiente:\n",
    "* True label 0 y Predicted label 0: True negatives - Casos negativos predichos exitosamente.\n",
    "* True label 1 y Predicted label 0: False negatives - Casos predichos como negativos que eran en realidad positivos.\n",
    "* True label 0 y Predicted label 1: False positives - Casos predichos como positivos que eran en realidad negativos.\n",
    "* True label 1 y Predicted label 1: True positives - Casos positivos predichos exitosamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se comporta de la misma manera en el conjunto de test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión para valores totales - dataset de predicción\n",
    "cm = plot_confusion_matrix(\n",
    "    clf,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cmap=plt.cm.Blues,\n",
    "    values_format=\".3f\",\n",
    "    #normalize=\"true\", # all, pred, true\n",
    ")\n",
    "cm.ax_.set_title(\"Matriz de confusión utilizando Regresión Logística\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuantos casos de Falsos Positivos? \n",
    "* ¿Cuantos casos de Falsos Negativos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETACIÓN DE LA LINEA BASE**\n",
    "\n",
    "* Considerando la predicción:\n",
    "  * Cuando se predice \"0\", el 91.9% de las predicciones son correctas (\"0\", no se vende).\n",
    "  * Cuando se predice \"1\", el 64.6% de las predicciones son correctas (\"1\", se vende).\n",
    "\n",
    "* Considerando el estado real:\n",
    "  * Del estado real \"0\", la predicción captura correctamente el 97.5% de los casos.\n",
    "  * Del estado real \"1\", la predicción captura correctamente el 34.9% de los casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar múltiples modelos utilizando todas estas cifras es complejo. \n",
    "Por eso se suele utilizar un único valor para compararlos. \n",
    "El **score** es una medida única del modelo, que tipicamente es el recall (wighted average recall):\n",
    "\n",
    "*The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.2 Utilizando otros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Probaremos distintos clasificadores para luego escoger el que mejor se ajusta a estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "classifiers_dict = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"KNN\": KNeighborsClassifier(3),\n",
    "    \"SVC\": SVC(kernel=\"linear\", C=0.025),\n",
    "    \"Decession Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for name, model in classifiers_dict.items():\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ]\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"El score del modelo utilizando {name} es {clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETACIÓN**:\n",
    "\n",
    "¿Qué modelo utilizaría?\n",
    "\n",
    "...\n",
    "\n",
    "Considere que no hemos ajustado los meta-parámetros de cada modelo. ¡La precisión de los modelos podría mejorar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.3 Encontrando  los mejores parámetros de un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases de estimador. Es posible y recomendable buscar en el espacio de hiperparámetros la mejor puntuación de validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Por ejemplo, utilizando un modelo _Support Vector Classifier_ realizaremos una búsqueda de los hiperparámetros `C` y `kernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    # Full - several combinations\n",
    "    #'classifier__C' : [0.01, 0.01, 1, 10, 100],\n",
    "    #'classifier__kernel': ('rbf', 'linear')\n",
    "    # Reducido\n",
    "    'classifier__C' : [0.25, 1, 25],   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# PACIENCIA: Ejecución toma cerca de 5-10 minutos.\n",
    "import time\n",
    "print(\"Realizando grid search...\")\n",
    "print(\"\\tpipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"\\tparameters:\")\n",
    "print(f\"\\t{param_grid}\")\n",
    "toc = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "tic = time.time()\n",
    "print(f\"Realizado en {tic-toc:0.1f} segundos\\n\")\n",
    "print(f\"Best score: {grid_search.best_score_:0.3f}\")\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(f\"\\t{param_name}: {best_parameters[param_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Puedes ver el resumen de la ejecución anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Como también el mejor estimador obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Si recuerdas, la métrica utilizada fue el _recall_, `scikit-learn` permite incluso calcular el `recall` para ambas etiquetas de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(grid_search.best_estimator_.predict(X_train), y_train, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(f\"El score del modelo es {clf.score(X_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, por buscar parámetros (en un espacio muy reducido) hemos aumentado el score del modelo desde 0.893 a 0.938, ¡superando a la regresión logística!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Podemos incluso volver a graficar la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cm = plot_confusion_matrix(\n",
    "    grid_search,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cmap=plt.cm.Blues,\n",
    "    values_format=\".3f\",\n",
    "    #normalize=\"all\", # all, pred, true\n",
    "\n",
    ")\n",
    "\n",
    "cm.ax_.set_title(\"Matriz de confusión utilizando GridSearchCV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox para calculos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretación de Negocio\n",
    "\n",
    "¿Cómo podemos interpretar los números anteriores?\n",
    "\n",
    "* Considerando la predicción:\n",
    "  * Se predicen 808 respuestas positivas (\"1\") y 7985 respuestas negativas (\"0\"): 8.9% de respuestas positivas. \n",
    "  * Cuando se predice \"0\", el 93.2% de las predicciones son correctas (\"0\", no se vende).\n",
    "  * Cuando se predice \"1\", el 61.1% de las predicciones son correctas (\"1\", se vende).\n",
    "\n",
    "* Considerando el estado real:\n",
    "  * Existen 1058 respuestas positivas (\"1\") y 7985 respuestas negativas (\"0\"): 11.7% de respuestas positivas. \n",
    "  * Del estado real \"0\", la predicción captura correctamente el 96.1% de los casos.\n",
    "  * Del estado real \"1\", la predicción captura correctamente el 46.7% de los casos.\n",
    "  \n",
    "Pensemos que se planteaba abordar una nueva campaña de marketing para 1000 personas. Históricamente, de éstas 1000 personas sólo un 11.7% terminaba adquiriendo el depósito a plazo, es decir, 117 personas.\n",
    "\n",
    "El modelo predictivo indica que sólo es necesario entrevistar a 89 personas, de las cuales 89 x 0.61 = 54 probablemente adquirirán el servicio. \n",
    "\n",
    "Supongamos que la campaña de marketing tiene un costo X, y que el banco tiene una ganancia de Y.\n",
    "\n",
    "* Modelo tradicional de Marketing presenta una ganancia de 117 Y - 1000 X.\n",
    "* Modelo de Machine Learning presenta una ganacia de  54 Y - 89 X.\n",
    "\n",
    "Es decir, es posible acceder a cerca de la mitad de la población objetivo concentrando el esfuerzo en menos del 10% del público total.\n",
    "\n",
    "En este caso, la segmentación ha sido \"absoluta\": 0 y 1. Si en lugar de eso se predice una propención a la compra (rango 0-100), es posible trabajar en una segmentación de mercado más eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Trabajos futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Algunas ideas interesantes para mejorar el modelo de clasificación pueden ser:\n",
    "\n",
    "- Obtener más datos, con tal que el algoritmo pueda _aprender_ de mejor manera.\n",
    "- Realizar _hyper-parameters tuning_ con más modelos, más parámetros e incluso con una grilla más fina (lo cual requiera mucho más tiempo poder de cómputo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encuesta:\n",
    "\n",
    "Responder la encuesta en el [enlace](https://forms.office.com/Pages/ResponsePage.aspx?id=zu7OdUTRPU-clJ5rQCX8_4qs5cX1Y7dFhVdiCz848sBURDdJNDRaNUFDUlJDWkJZNlhKUjRZUktOSy4u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
